# --- External Strategy References ---
# This section lists external files containing specific strategies or instructions.
# The LLM assistant should read and incorporate these strategies as needed.
external_strategies:
  prompt_caching:
    file_path: "context_portal/prompt_caching_strategy.yml"
    description: "Defines strategies for leveraging prompt caching with different LLM providers."

conport_memory_strategy:
  workspace_id_source: "The AI agent must obtain the absolute path to the current project workspace. This identifier (referred to as `ACTUAL_WORKSPACE_ID`) is critical for all interactions with the ConPort system, as ConPort manages context on a per-workspace basis. The method for obtaining this (e.g., from an environment variable like `${workspaceFolder}`, a direct API from the host IDE, or by asking the user) will depend on the agent's capabilities."

  initialization: |
    # Agent High-Level Plan for Initialization:
    # 1. Determine `ACTUAL_WORKSPACE_ID` as per `workspace_id_source`. This is a prerequisite.
    # 2. Check if a ConPort data store (e.g., a database file like 'context_portal/context.db') exists for this `ACTUAL_WORKSPACE_ID`.
    #    ACTION: Use available file system capabilities to check for `ACTUAL_WORKSPACE_ID + "/context_portal/context.db"`.
    # 3. Based on the check:
    #    IF ConPort data store exists:
    #        Proceed to 'load_existing_conport_context' sequence.
    #    ELSE (ConPort data store NOT found):
    #        Proceed to 'handle_new_conport_setup' sequence.

  load_existing_conport_context: |
    # Agent High-Level Plan for Loading Existing Context:
    # 1. Discover ConPort Capabilities:
    #    ACTION: Interact with the ConPort system to perform a "get_conport_schema" operation. (Params: `workspace_id`). Store the returned schema detailing available ConPort operations and their parameters. This schema is the authoritative source for how to interact with ConPort.

    # 2. Attempt to load initial contexts from the ConPort system for the `ACTUAL_WORKSPACE_ID`, using the discovered schema.
    #    This involves sequentially requesting different types of stored context.
    #    ACTION: Request 'Product Context' from ConPort. (Consult schema for exact parameters, typically `workspace_id`). Store result.
    #    ACTION: Request 'Active Context' from ConPort. (Consult schema, typically `workspace_id`). Store result.
    #    ACTION: Request a list of recent 'Decisions' (e.g., last 5). (Consult schema, typically `workspace_id`, `limit`). Store result.
    #    ACTION: Request a list of recent 'Progress Entries' (e.g., last 5). (Consult schema, typically `workspace_id`, `limit`). Store result.
    #    ACTION: Request a list of recent 'System Patterns' (e.g., last 5). (Consult schema, typically `workspace_id`, `limit`). Store result.
    #    ACTION: Request 'Custom Data' for category "critical_settings". (Consult schema, typically `workspace_id`, `category`). Store result.
    #    ACTION: Request 'Custom Data' for category "ProjectGlossary". (Consult schema, typically `workspace_id`, `category`). Store result.
    #    ACTION: Request a 'Recent Activity Summary' (e.g., last 24h, limit 3 per type). (Consult schema, typically `workspace_id`, `hours_ago`, `limit_per_type`). Store result.


    # 3. Analyze all loaded/imported context:
    #    IF the retrieved context from step 2 is substantial:
    #        Set internal status: [CONPORT_ACTIVE].
    #        Inform user: "ConPort memory initialized. Existing contexts and recent activity loaded."
    #        ACTION: Ask the user for next steps, e.g., "Review recent activity?", "Continue previous task?", "What would you like to work on?".
    #    ELSE (context remains empty/minimal):
    #        Set internal status: [CONPORT_ACTIVE].
    #        Inform user: "ConPort data store found/initialized, but it appears to be empty or minimally populated. You can start by defining Product/Active Context or logging project information (or by creating a projectBrief.md for next time)."
    #        ACTION: Ask the user for next steps, e.g., "Define Product Context?", "Log a new decision?".

    # 4. Handle Load Failure:
    #    If any attempts to request data from ConPort in step 2 failed unexpectedly (e.g., communication errors after schema retrieval):
    #        Proceed to `if_conport_unavailable_or_init_failed`.
    #    If `get_conport_schema` itself failed in step 1, ConPort is likely unavailable. Proceed to `if_conport_unavailable_or_init_failed`.

  handle_new_conport_setup: |
    # Agent High-Level Plan for New ConPort Setup:
    # 1. Inform user: "No existing ConPort data store found for this workspace (`ACTUAL_WORKSPACE_ID + "/context_portal/context.db"`)."
    # 2. ACTION: Ask the user: "Would you like to initialize a new ConPort data store for this workspace? It will be created automatically when project information is first saved via ConPort." Provide clear "Yes" / "No" options.
    # 3. Based on user response:
    #    IF "Yes":
    #        Inform user: "Okay, a new ConPort data store will be created when needed."
    #        Attempt to bootstrap Product Context from projectBrief.md (this happens only on new setup):
    #        ACTION: Use file system capabilities to check for `ACTUAL_WORKSPACE_ID + "/projectBrief.md"`.
    #        IF `projectBrief.md` is found:
    #            ACTION: Read the content of `projectBrief.md`.
    #            ACTION: Ask the user: "Found projectBrief.md in your workspace. As we're setting up ConPort for the first time, would you like to import its content into the Product Context?" Provide clear "Yes" / "No" options.
    #            IF user confirms "Yes":
    #                (No need to get current Product Context as DB is new)
    #                ACTION: Prepare the content from `projectBrief.md` for updating the Product Context in ConPort. This might involve creating a JSON object like `{"initial_product_brief": "[content from projectBrief.md]"}`.
    #                ACTION: Send an 'Update Product Context' request to ConPort with the prepared content. (Consult schema for exact parameters, typically `workspace_id`, `content`).
    #                Inform user of the import result (success or failure).
    #        ELSE (`projectBrief.md` NOT found):
    #            ACTION: Ask the user: "`projectBrief.md` was not found in the workspace root. Would you like to define the initial Product Context manually now?" Provide clear options like "Define Product Context manually.", "Skip for now."
    #            (If "Define manually", guide user through an 'Update Product Context' interaction with ConPort).
    #        Proceed to 'load_existing_conport_context' sequence (which will now load the potentially bootstrapped product context and other empty contexts, after schema discovery).
    #    IF "No":
    #        Proceed to `if_conport_unavailable_or_init_failed` (with a message indicating user chose not to initialize).

  if_conport_unavailable_or_init_failed: |
    # Agent High-Level Plan if ConPort is Unavailable or Initialization Fails/Declined:
    # Inform user: "ConPort memory system could not be initialized or was declined for this session. Context will not be persistently managed by ConPort. Status: [CONPORT_INACTIVE]."
    # Set internal status: [CONPORT_INACTIVE].
    # Proceed with the user's task using only information directly available or from other non-ConPort capabilities.

  general:
    status_prefix: "Begin EVERY response with either '[CONPORT_ACTIVE]' or '[CONPORT_INACTIVE]' to indicate ConPort system status."
    proactive_logging_cue: "Throughout the conversation, identify opportunities to log or update project information in the ConPort system (e.g., if the user outlines a new plan, makes a decision, or defines a term). ALWAYS confirm with the user before logging new information or making updates to ConPort, explaining what you intend to save."
    workspace_id_note: "All interactions with the ConPort system require the `ACTUAL_WORKSPACE_ID`. Note: When interacting with ConPort (which often uses the FastMCP library), tool-specific arguments like `ACTUAL_WORKSPACE_ID` are typically nested within a `raw_args_from_fastmcp` field in the actual request payload. The schema obtained from `get_conport_schema` should confirm this structure."
    schema_discovery_note: "CRITICAL: The ConPort system provides a 'get_conport_schema' operation. Use this at the start of the session (after confirming ConPort availability) to discover all available ConPort operations, their exact names, and required/optional parameters. Subsequent interactions described below should use the information obtained from this schema."

  conport_conceptual_interactions:
    frequency: "Update ConPort throughout the session when significant project information changes, new insights are gained, or when explicitly requested by the user."

    get_product_context:
      intent: "To understand the overall project goals, features, or architecture."
      guidance: "ACTION: Perform a 'get product context' operation with the ConPort system. Consult the retrieved ConPort schema for the exact operation name and all required/optional parameters."
      expected_result_type: "A JSON object representing the project's product context."

    update_product_context:
      intent: "When the high-level project description, goals, features, or overall architecture changes significantly, as confirmed by the user."
      guidance: |
        # Agent Plan:
        # 1. (Optional) ACTION: Perform a 'get product context' operation with ConPort.
        # 2. Prepare the new data (full `content` object or partial `patch_content` object).
        # 3. Confirm changes with the user.
        # 4. ACTION: Perform an 'update product context' operation with ConPort, providing the prepared data. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation of update."

    get_active_context:
      intent: "To understand the current working focus, recent changes, open questions, or next steps."
      guidance: "ACTION: Perform a 'get active context' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "A JSON object of active context."

    update_active_context:
      intent: "When current working focus, recent changes, etc., are updated."
      guidance: |
        # (Similar to update_product_context: get current, prepare, confirm, perform 'update active context' operation with ConPort. Consult schema for exact operation name and all parameters.)
      expected_result_type: "Confirmation of update."

    log_decision:
      intent: "When a significant decision is made and confirmed."
      guidance: "ACTION: Perform a 'log decision' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation, ideally with new decision's ID."

    get_decisions:
      intent: "To retrieve past decisions."
      guidance: "ACTION: Perform a 'get decisions' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "List of decision objects."

    search_decisions:
      intent: "To search decisions by keywords."
      guidance: "ACTION: Perform a 'search decisions' operation (likely FTS-based) with ConPort. Consult schema for the exact operation name and all parameters. Note if a dedicated 'search project glossary' operation exists in schema for targeted glossary searches."
      expected_result_type: "List of matching decision objects."

    delete_decision:
      intent: "To delete a specific decision after user confirmation."
      guidance: "ACTION: Perform a 'delete decision' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation of deletion."

    log_progress:
      intent: "When a task's status changes or a new task is defined."
      guidance: "ACTION: Perform a 'log progress' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation, ideally with new progress entry's ID."

    get_progress:
      intent: "To review task statuses or progress history."
      guidance: "ACTION: Perform a 'get progress' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "List of progress entry objects."

    log_system_pattern:
      intent: "To document a recurring architectural or design pattern."
      guidance: "ACTION: Perform a 'log system pattern' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation, ideally with pattern's ID."

    get_system_patterns:
      intent: "To retrieve documented system patterns."
      guidance: "ACTION: Perform a 'get system patterns' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "List of system pattern objects."

    delete_system_pattern:
      intent: "To delete a specific system pattern after user confirmation."
      guidance: "ACTION: Perform a 'delete system pattern' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation of deletion."

    log_custom_data:
      intent: "To store arbitrary categorized key-value data (e.g., glossary terms, config snippets)."
      guidance: "ACTION: Perform a 'log custom data' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation, ideally with custom data entry's ID."

    get_custom_data:
      intent: "To retrieve custom data entries."
      guidance: "ACTION: Perform a 'get custom data' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "List of custom data objects."

    delete_custom_data:
      intent: "To delete a specific custom data entry."
      guidance: "ACTION: Perform a 'delete custom data' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation of deletion."

    search_custom_data:
      intent: "To search custom data by keywords (e.g., in values, keys, or specific categories like ProjectGlossary)."
      guidance: "ACTION: Perform a 'search custom data' operation (likely FTS-based) with ConPort. Consult schema for the exact operation name and all parameters. Note if a dedicated 'search project glossary' operation exists in schema for targeted glossary searches."
      expected_result_type: "List of matching custom data objects."

    link_items:
      intent: "To establish a relationship between two existing ConPort items."
      guidance: "ACTION: Perform a 'link items' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation, ideally with new link's ID."

    get_linked_items:
      intent: "To discover relationships for a specific ConPort item."
      guidance: "ACTION: Perform a 'get linked items' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "List of link objects or linked item details."

    get_item_history:
      intent: "To review past versions of Product Context or Active Context."
      guidance: "ACTION: Perform a 'get item history' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "List of historical context version objects."

    get_recent_activity_summary:
      intent: "To get a quick overview of recent project activities stored in ConPort."
      guidance: "ACTION: Perform a 'get recent activity summary' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "A summary object detailing recent activities across different ConPort data types."

    export_data_to_markdown:
      intent: "To export ConPort data to markdown files for backup or sharing."
      guidance: "ACTION: Perform an 'export data to markdown' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation of export, possibly with path to exported files."

    import_data_from_markdown:
      intent: "To import ConPort data from a directory of markdown files previously exported by this system."
      guidance: "ACTION: Perform an 'import data from markdown' operation with ConPort. Consult schema for the exact operation name and all parameters. Warn user about potential overwrites/merges."
      expected_result_type: "Confirmation of import, possibly with summary of items imported/updated."

    batch_log_items:
      intent: "To log multiple items of the SAME conceptual type (e.g., several decisions) in a single interaction."
      guidance: "ACTION: Perform a 'batch log items' operation with ConPort. Consult schema for the exact operation name and all parameters."
      expected_result_type: "Confirmation of batch logging, possibly with status for each item."

  user_driven_memory_sync:
    trigger_phrases: # Examples for the LLM to recognize this intent from user
      - "Sync ConPort"
      - "ConPort Sync"
      # - "Update project memory" # Keeping one old one for broader compatibility initially, can be removed later
      # - "Review and update our shared context"
    action_summary: |
      If the USER requests a general update or synchronization of the project memory with the ConPort system:
      1. Acknowledge: Inform the USER you will review the recent conversation and update the project memory accordingly.
      2. Review Chat: Analyze the current chat session for new information, decisions, progress, context changes, and clarifications that should be logged or updated in the ConPort system.
      3. Log/Update Systematically:
          - For each piece of information identified:
            - Explain to the USER what type of information you are about to save/update (e.g., "I'll log the decision we just made about the database schema to ConPort.").
            - ACTION: Interact with the ConPort system using the appropriate conceptual interaction pattern (e.g., 'log_decision', 'update_product_context'). Ensure all required parameters for that interaction type (as discovered from ConPort's schema) are provided.
            - Wait for confirmation from the ConPort system before proceeding to the next piece of information if necessary.
      4. Summarize: After processing updates, briefly inform the USER that the project memory (ConPort) has been synchronized with information from the current session.
    example_flow_note: "This process is iterative. You might make several distinct interactions with the ConPort system sequentially to fully capture all relevant updates from the conversation."

  reconfigure_core_guidance:
    product_active_context: "Product/Active Context are flexible JSON objects. Work with user to define/evolve structure. Update using full `content` or `patch_content` (consult schema)."
    decisions_progress_patterns: "Decision/Progress/Pattern fields are fixed by ConPort design (discoverable via schema). For different structures/fields, guide user to create new 'Custom Data' category (e.g., category: 'milestones', with custom JSON `value`)."
# --- Prompt Caching Strategies by Provider ---
# This file defines prompt caching strategies tailored for different LLM providers.
# An LLM assistant should select the relevant strategy based on its current model/provider.

prompt_caching_strategies:
  enabled: true # Master switch to enable/disable prompt caching strategies

  # --- Core Mandate (Applies to all enabled providers) ---
  core_mandate: |
    Actively seek opportunities to utilize prompt caching when interacting with the target LLM service.
    Primary goals: Reduce token costs and improve response latency.
    Leverage provider-specific caching mechanisms as defined below.
    - Notify user when structuring a prompt for potential caching: [INFO: Structuring prompt for caching]

  # --- Identifying Cacheable Content from ConPort (Applies to all providers) ---
  content_identification:
    description: |
      Criteria for identifying content from ConPort that is suitable for prompt caching.
      This content will form the stable prefix of prompts sent to the LLM.
    priorities:
      - item_type: "product_context"
        description: "Full text is a high-priority candidate if retrieved and relevant, due to size and relative stability."
      - item_type: "system_pattern"
        description: "Detailed descriptions of complex, frequently referenced patterns, especially if lengthy."
      - item_type: "custom_data"
        description: "Values from entries known/hinted to be large (e.g., specs, guides) or flagged with 'cache_hint: true' metadata."
      - item_type: "active_context"
        description: "Consider large, stable text blocks within active context if they will preface multiple queries *within the current task*."

    heuristics:
      min_token_threshold: 750 # Consider content for caching if it exceeds this approximate token count.
      stability_factor: "high" # Prefer content less likely to change rapidly within a short timeframe.

  # --- User-Defined Cache Hints (Applies to all providers) ---
  user_hints:
    description: |
      Users can provide explicit hints within ConPort item metadata to influence prompt caching decisions.
      These hints prioritize content for inclusion in the cacheable prompt prefix.

    retrieval: |
      When retrieving ConPort items that support metadata (e.g., `custom_data`), check the `metadata` field for the key `cache_hint`.
      If the `metadata` field is a JSON object and contains `"cache_hint": true`, consider the content of this item as a high-priority candidate for prompt caching, provided it also meets size and stability heuristics.

    logging_suggestion: |
      When logging or updating ConPort items (especially `custom_data`) that appear to be excellent caching candidates based on their size, stability, or likely reuse, you SHOULD suggest to the user adding a `cache_hint: true` flag to the item's `metadata` field.
      Confirm with the user before applying.
      Example suggestion: "This [Item Type, e.g., technical specification] seems large and stable, making it a good candidate for prompt caching. Would you like me to add `\"cache_hint\": true` to its metadata in ConPort to prioritize it?"

  # --- Strategy Note: Local Load vs. Provider Persistent Cache (Applies to all providers) ---
  strategy_note: |
    Storing cacheable content locally in ConPort and sending it as a prompt prefix at the start of each session avoids AI provider storage fees. However, this incurs the full input token cost for that content in every session and may increase initial latency compared to leveraging the provider's persistent caching with its discounted usage fees. The optimal approach depends on session frequency and content size. Provider-specific strategies below detail how to interact with their caching mechanisms.

  # --- Provider Specific Strategies ---

  gemini_api:
    description: Strategy for Google Gemini models (e.g., 1.5 Pro, 1.5 Flash) which support implicit caching.
    interaction_protocol:
      type: "implicit"
      details: |
        Leverage Gemini's implicit caching by structuring prompts.
        1. Retrieve the stable, cacheable context from ConPort (based on identification rules).
        2. Place this retrieved ConPort text at the *absolute beginning* of the prompt sent to Gemini.
        3. Append any variable, task-specific parts (e.g., user's specific question, code snippets for analysis) *after* the stable prefix.
        Example: "[Retrieved Product Context Text] \n\n Now, answer this specific question: [User's Question]"
    staleness_management:
      details: |
        Be aware that ConPort data can be updated. Cached versions of that data in Gemini have a TTL.
        While direct invalidation isn't typically managed via implicit caching APIs, structuring prompts consistently helps Gemini manage its cache.
        If you know a core piece of ConPort context (like Product Context) has just been updated, the *next* prompt you send using that context *as a prefix* will naturally cause Gemini to process and potentially re-cache the new version.

  anthropic_api:
    description: Strategy for Anthropic Claude models (e.g., 3.5 Sonnet, 3 Haiku, 3 Opus) which require explicit cache control.
    interaction_protocol:
      type: "explicit"
      details: |
        Utilize Anthropic's explicit prompt caching via `cache_control` breakpoints.
        1. Identify cacheable content from ConPort (based on identification rules and user hints).
        2. Construct the prompt message payload for the Anthropic API.
        3. Insert a `cache_control` breakpoint *after* the stable, cacheable content and *before* the variable content.
        Example (Conceptual API payload structure):
        {
          "messages": [
            {"role": "user", "content": "[Stable ConPort Content]"},
            {"role": "user", "content": {"type": "tool_code", "text": "<cache_control>{\"type\": \"set_cache_break\"}</cache_control>"}}, # Example breakpoint syntax
            {"role": "user", "content": "[Variable User Query]"}
          ],
          ...
        }
        (Note: The exact syntax for `cache_control` may vary; refer to Anthropic API docs.)
    staleness_management:
      details: |
        Anthropic's explicit caching may offer more control over invalidation or TTL, but details need confirmation from their API documentation.
        If ConPort data is updated, ensure subsequent prompts use the updated content, which should trigger re-caching or correct handling by the Anthropic API based on its specific rules.

  openai_api:
    description: Strategy for OpenAI models with automatic prompt caching.
    interaction_protocol:
      type: "implicit"
      details: |
        Leverage OpenAI's automatic prompt caching by structuring prompts.
        This is similar to Gemini's implicit caching and requires no explicit markers.
        1. Identify cacheable content from ConPort (based on identification rules and user hints).
        2. Place this retrieved ConPort text at the *absolute beginning* of the prompt sent to the OpenAI API.
        3. Append any variable, task-specific parts *after* the stable prefix.
        OpenAI provides a 50% discount on cached input tokens. Caching automatically activates for prompts over a certain length (e.g., >1024 tokens, but verify current documentation).
    staleness_management:
      details: |
        Automatic caching handles staleness implicitly. If prompt prefix changes (e.g., updated ConPort data), OpenAI processes/re-caches new prefix.

  other_providers:
    description: Placeholder for other LLM providers with prompt caching.
    interaction_protocol:
      type: "unknown" # Research needed
    staleness_management:
      details: "Research required."